{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNAaFVsSOhItUd+BD5p8Jwa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BrutFab/ppo_BipedalWalker_v3/blob/main/ppo_BipedalWalker_v3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. Setup**\n"
      ],
      "metadata": {
        "id": "6MbMQP0b7zGg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Install Packages**"
      ],
      "metadata": {
        "id": "gg4Vl1FH_yVm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oyYkz0Vc7xNE"
      },
      "outputs": [],
      "source": [
        "# Install necessary packages\n",
        "!apt install swig cmake ffmpeg xvfb python3-opengl\n",
        "!pip install stable-baselines3==2.0.0a5 gymnasium[box2d] huggingface_sb3 pyvirtualdisplay imageio[ffmpeg]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Next Cell will force the notebook runtime to restart. This is to ensure all the new libraries installed will be used."
      ],
      "metadata": {
        "id": "-v81BfAd7yWc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.kill(os.getpid(), 9)"
      ],
      "metadata": {
        "id": "FaiyY-Fn_EZg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Start Virtual Display**"
      ],
      "metadata": {
        "id": "DAlous3h_OrZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyvirtualdisplay import Display\n",
        "virtual_display = Display(visible=0, size=(1400, 900))\n",
        "virtual_display.start()"
      ],
      "metadata": {
        "id": "xblUYFLM_ZGr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Setup Environment**"
      ],
      "metadata": {
        "id": "cG91Uw14_9-W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ddhvmlKeLh-H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gymnasium as gym\n",
        "env = gym.make(\"BipedalWalker-v3\", hardcore=True)\n",
        "env.reset()"
      ],
      "metadata": {
        "id": "FyLRt45mACyY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Observation Space**\n",
        "Observation Space Shape (24,) vector of size 24, where each value contains different information about the walker:\n",
        "\n",
        "- **Hull Angle Speed**: The speed at which the main body of the walker is rotating.\n",
        "- **Angular Velocity**: The rate of change of the angular position of the walker.\n",
        "- **Horizontal Speed**: The speed at which the walker is moving horizontally.\n",
        "- **Vertical Speed**: The speed at which the walker is moving vertically.\n",
        "- **Position of Joints**: The positions (angles) of the walker's joints. Given that the walker has 4 joints, this take up 4 values.\n",
        "- **Joints Angular Speed**: The rate of change of the angular position for each joint. Again, this would be 4 values for the 4 joints.\n",
        "- **Legs Contact with Ground**: Indicating whether each leg is in contact with the ground. Given two legs, this contains 2 values.\n",
        "- **10 Lidar Rangefinder Measurements**: These are distance measurements to detect obstacles or terrain features around the walker. There are 10 of these values.\n"
      ],
      "metadata": {
        "id": "xr8LRvHOLxIx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"_____OBSERVATION SPACE_____ \\n\")\n",
        "print(\"Observation Space Shape\", env.observation_space.shape)\n",
        "print(\"Sample observation\", env.observation_space.sample()) # Get a random observation"
      ],
      "metadata": {
        "id": "l23gcNuzLr4h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Action Space**\n",
        "\n",
        " Actions are motor speed values in the [-1, 1] range for each of the 4 joints at both hips and knees."
      ],
      "metadata": {
        "id": "aS3kPiz8I7OH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n _____ACTION SPACE_____ \\n\")\n",
        "print(\"Action Space Shape\", env.action_space.shape)\n",
        "print(\"Action Space Sample\", env.action_space.sample()) # Take a random action"
      ],
      "metadata": {
        "id": "r8-of2O-KXe_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Vectorized Environment**\n",
        "Create a vectorized environment (a method for stacking multiple independent environments into a single environment) of 16 environments to have more diverse experiences."
      ],
      "metadata": {
        "id": "WFheIWeIMR8F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from stable_baselines3.common.env_util import make_vec_env\n",
        "env = make_vec_env('BipedalWalker-v3', n_envs=16)"
      ],
      "metadata": {
        "id": "G9LsgYvuMqTB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. Building the Model**"
      ],
      "metadata": {
        "id": "Ho3QSAXWNOxF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from stable_baselines3 import PPO\n",
        "model = PPO(\n",
        "    policy = 'MlpPolicy',\n",
        "    env = env,\n",
        "    n_steps = 2048,\n",
        "    batch_size = 128,\n",
        "    n_epochs = 6,\n",
        "    gamma = 0.999,\n",
        "    gae_lambda = 0.98,\n",
        "    ent_coef = 0.01,\n",
        "    verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n5amWvjFNt93",
        "outputId": "1f5c7403-676b-4e23-ec84-48cd9b4d6539"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3.**Video Generation**"
      ],
      "metadata": {
        "id": "LyYbio5uOiHb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from wasabi import Printer\n",
        "import numpy as np\n",
        "from stable_baselines3.common.base_class import BaseAlgorithm\n",
        "from pathlib import Path\n",
        "import tempfile\n",
        "from stable_baselines3.common.monitor import Monitor\n",
        "from stable_baselines3.common.vec_env import (\n",
        "    DummyVecEnv,\n",
        "    VecEnv,\n",
        "    VecVideoRecorder,\n",
        ")"
      ],
      "metadata": {
        "id": "bZpJ_3yHOhce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "msg = Printer()"
      ],
      "metadata": {
        "id": "r0XIO_k5PBPc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_replay(\n",
        "    model: BaseAlgorithm,\n",
        "    eval_env: VecEnv,\n",
        "    video_length: int,\n",
        "    is_deterministic: bool,\n",
        "    local_path: Path,\n",
        "):\n",
        "    \"\"\"\n",
        "    Generate a replay video of the agent\n",
        "    :param model: trained model\n",
        "    :param eval_env: environment used to evaluate the agent\n",
        "    :param video_length: length of the video (in timesteps)\n",
        "    :param is_deterministic: use deterministic or stochastic actions\n",
        "    :param local_path: path of the local repository\n",
        "    \"\"\"\n",
        "    # This is another temporary directory for video outputs\n",
        "    # SB3 created a -step-0-to-... meta files as well as other\n",
        "    # artifacts which we don't want in the repo.\n",
        "    with tempfile.TemporaryDirectory() as tmpdirname:\n",
        "        # Step 1: Create the VecVideoRecorder\n",
        "        env = VecVideoRecorder(\n",
        "            eval_env,\n",
        "            tmpdirname,\n",
        "            record_video_trigger=lambda x: x == 0,\n",
        "            video_length=video_length,\n",
        "            name_prefix=\"\",\n",
        "        )\n",
        "\n",
        "        obs = env.reset()\n",
        "        lstm_states = None\n",
        "        episode_starts = np.ones((env.num_envs,), dtype=bool)\n",
        "\n",
        "        try:\n",
        "            for _ in range(video_length):\n",
        "                action, lstm_states = model.predict(\n",
        "                    obs,\n",
        "                    state=lstm_states,\n",
        "                    episode_start=episode_starts,\n",
        "                    deterministic=is_deterministic,\n",
        "                )\n",
        "                obs, _, episode_starts, _ = env.step(action)\n",
        "\n",
        "            # Save the video\n",
        "            env.close()\n",
        "\n",
        "            # Convert the video with x264 codec\n",
        "            inp = env.video_recorder.path\n",
        "            out = local_path\n",
        "            os.system(f\"ffmpeg -y -i {inp} -vcodec h264 {out}\".format(inp, out))\n",
        "            print(f\"Video saved to: {out}\")\n",
        "        except KeyboardInterrupt:\n",
        "            pass\n",
        "        except Exception as e:\n",
        "            msg.fail(str(e))\n",
        "            # Add a message for video\n",
        "            msg.fail(\n",
        "                \"We are unable to generate a replay of your agent\"\n",
        "            )"
      ],
      "metadata": {
        "id": "TbXxg6viPC-u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4. Training, Saving and Record the Videos**"
      ],
      "metadata": {
        "id": "7FSBntjZWBZC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os"
      ],
      "metadata": {
        "id": "V95RlWJ8Staf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create a directory to save the videos\n",
        "video_dir = \"/content/videos\"\n",
        "if not os.path.exists(video_dir):\n",
        "    os.makedirs(video_dir)"
      ],
      "metadata": {
        "id": "usp5BKC4dlh8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env_id = \"BipedalWalker-v3\"\n",
        "# Train and generate video at every 100000 steps, adjust the timesteps to your liking\n",
        "for i in range(0, 20000, 1000):\n",
        "    model.learn(total_timesteps=1000)\n",
        "    # Save the model\n",
        "    model_name = \"ppo-BipedalWalker-v3\"\n",
        "    model.save(model_name)\n",
        "    video_name = f\"replay_{i + 1000}.mp4\"\n",
        "    generate_replay(\n",
        "        model=model,\n",
        "        eval_env=DummyVecEnv([lambda: Monitor(gym.make(env_id, hardcore=True, render_mode=\"rgb_array\"))]),\n",
        "        video_length=100,\n",
        "        is_deterministic=True,\n",
        "        local_path=os.path.join(video_dir, video_name)\n",
        "    )\n",
        "\n",
        "model_name = \"ppo-BipedalWalker-v3\"\n",
        "model.save(model_name)\n"
      ],
      "metadata": {
        "id": "vh3qOQq5QGlH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(os.path.join(video_dir, \"filelist.txt\"), \"w\") as f:\n",
        "    for i in range(0, 20000, 1000):\n",
        "        video_name = f\"replay_{i + 1000}.mp4\"\n",
        "        f.write(f\"file '{os.path.join(video_dir, video_name)}'\\n\")\n",
        "# Concatenate all the videos into one\n",
        "os.system(f\"ffmpeg -f concat -safe 0 -i {os.path.join(video_dir, 'filelist.txt')} -c copy {os.path.join(video_dir, 'replay_all.mp4')}\")"
      ],
      "metadata": {
        "id": "Kgoz0bk_WyHD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **5. Visualize Final Video**"
      ],
      "metadata": {
        "id": "zw4c5jJ0XBWU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "mp4 = open('videos/replay_all.mp4','rb').read()\n",
        "data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "HTML(\"\"\"\n",
        "<video width=600 controls>\n",
        "      <source src=\"%s\" type=\"video/mp4\">\n",
        "</video>\n",
        "\"\"\" % data_url)"
      ],
      "metadata": {
        "id": "NVFpJPohU2_Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **6. Evaluate the Model**"
      ],
      "metadata": {
        "id": "JvCZEk2DXnPa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from stable_baselines3.common.evaluation import evaluate_policy"
      ],
      "metadata": {
        "id": "JO0spFR9VEX2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval_env = Monitor(gym.make(\"BipedalWalker-v3\"))\n",
        "mean_reward, std_reward = evaluate_policy(model, eval_env, n_eval_episodes=10, deterministic=True)\n",
        "print(f\"mean_reward={mean_reward:.2f} +/- {std_reward}\")"
      ],
      "metadata": {
        "id": "AfCcrkOXXX3Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **7. Upload to HuggingFace**"
      ],
      "metadata": {
        "id": "7cfrtAWyVL_3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_sb3 import load_from_hub, package_to_hub\n",
        "from huggingface_hub import notebook_login # To log to our Hugging Face account to be able to upload models to the Hub."
      ],
      "metadata": {
        "id": "IG8ROyR3VY41"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "notebook_login()\n",
        "!git config --global credential.helper store"
      ],
      "metadata": {
        "id": "m8nEEiAHVcPD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env_id = \"BipedalWalker-v3\"\n",
        "model_name = \"ppo-BipedalWalker-v3\"\n",
        "model_architecture = \"PPO\"\n",
        "\n",
        "repo_id = \"YoungMeng/ppo-BipedalWalker-test\" # Change with your repo id\n",
        "\n",
        "## Define the commit message\n",
        "commit_message = \"Upload PPO BipedalWalker-v3 trained agent\"\n",
        "\n",
        "# Create the evaluation env and set the render_mode=\"rgb_array\"\n",
        "eval_env = DummyVecEnv([lambda: gym.make(env_id, hardcore=True, render_mode=\"rgb_array\")])\n",
        "\n",
        "package_to_hub(model=model, # trained model\n",
        "               model_name=model_name, # The name of our trained model\n",
        "               model_architecture=model_architecture, # The model architecture we used: in our case PPO\n",
        "               env_id=env_id, # Name of the environment\n",
        "               eval_env=eval_env,\n",
        "               repo_id=repo_id,\n",
        "               commit_message=commit_message)"
      ],
      "metadata": {
        "id": "WbKno-jkVhAi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **8. Load Models from HuggingFace (Optional)**"
      ],
      "metadata": {
        "id": "UupZDo6VVxM9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_sb3 import load_from_hub\n",
        "repo_id = \"YoungMeng/ppo-BipedalWalker-test\" # The repo_id\n",
        "filename = \"ppo-BipedalWalker-v3.zip\" # The model filename.zip\n",
        "\n",
        "checkpoint = load_from_hub(repo_id, filename)\n",
        "model = PPO.load(checkpoint, print_system_info=True)"
      ],
      "metadata": {
        "id": "_SlwpHkfVwk3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval_env = Monitor(gym.make(\"BipedalWalker-v3\", hardcore=True))\n",
        "mean_reward, std_reward = evaluate_policy(model, eval_env, n_eval_episodes=10, deterministic=True)\n",
        "print(f\"mean_reward={mean_reward:.2f} +/- {std_reward}\")"
      ],
      "metadata": {
        "id": "-E5xvraDV7ah"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}